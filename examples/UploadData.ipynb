{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f56a9b3",
   "metadata": {},
   "source": [
    "# Upstream Data Upload Guide\n",
    "\n",
    "## Overview\n",
    "\n",
    "This guide demonstrates how to authenticate with the Upstream API and upload sensor data using CSV files for environmental monitoring campaigns.\n",
    "\n",
    "## What You Can Do\n",
    "\n",
    "The Upstream API allows you to:\n",
    "- Authenticate and obtain access tokens\n",
    "- Upload sensor definitions and measurement data\n",
    "- Manage environmental monitoring campaigns\n",
    "- Query and retrieve measurement data\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Valid Upstream account credentials\n",
    "- Python 3.7+ with `requests` library installed\n",
    "- CSV files with sensor and measurement data formatted correctly\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install requests\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee1efa",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "\n",
    "1. **Authenticate** with the API to get your access token\n",
    "2. **Prepare your CSV files** following the required format\n",
    "3. **Upload your data** using the provided functions\n",
    "4. **Monitor the results** and verify successful upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de5ed4d-505a-4a59-b15a-7de41e8246d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "from typing import Dict, Any, Optional, List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65443e09",
   "metadata": {},
   "source": [
    "## 1. Authentication\n",
    "\n",
    "First, we need to authenticate with the Upstream API to obtain an access token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b250831-bec9-4425-b165-127e49d76ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Upstream API Authentication ===\n",
      "âœ… Authentication successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def authenticate_upstream(base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\") -> str:\n",
    "    \"\"\"\n",
    "    Authenticate with Upstream API and return access token.\n",
    "    \n",
    "    Args:\n",
    "        base_url: Base URL for the Upstream API (dev or prod)\n",
    "        \n",
    "    Returns:\n",
    "        Access token string\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If authentication fails\n",
    "    \"\"\"\n",
    "    auth_url = f\"{base_url}/api/v1/token\"\n",
    "    \n",
    "    print(\"=== Upstream API Authentication ===\")\n",
    "    credentials = {\n",
    "        \"username\": input(\"Username: \"),\n",
    "        \"password\": getpass.getpass(\"Password: \")\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(auth_url, data=credentials)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        token = response.json().get(\"access_token\")\n",
    "        if not token:\n",
    "            raise Exception(\"No access token in response\")\n",
    "            \n",
    "        print(\"âœ… Authentication successful!\")\n",
    "        return token\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Authentication failed: {e}\")\n",
    "\n",
    "# Get authentication token\n",
    "token = authenticate_upstream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c608a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_authenticated_request(\n",
    "    method: str,\n",
    "    url: str,\n",
    "    token: str,\n",
    "    json: Optional[Dict] = None,\n",
    "    files: Optional[Dict] = None,\n",
    "    params: Optional[Dict] = None\n",
    ") -> requests.Response:\n",
    "    \"\"\"\n",
    "    Make an authenticated HTTP request to the Upstream API.\n",
    "    \n",
    "    Args:\n",
    "        method: HTTP method (GET, POST, PUT, DELETE, etc.)\n",
    "        url: Full URL for the request\n",
    "        token: Authentication token\n",
    "        json: JSON data for the request body\n",
    "        files: Files for multipart upload\n",
    "        params: URL parameters\n",
    "        \n",
    "    Returns:\n",
    "        Response object from the request\n",
    "        \n",
    "    Raises:\n",
    "        requests.exceptions.HTTPError: If the request fails\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "    }\n",
    "    \n",
    "    # Don't set Content-Type for file uploads (requests will set it automatically)\n",
    "    if files is None:\n",
    "        headers[\"Content-Type\"] = \"application/json\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.request(\n",
    "            method=method.upper(),\n",
    "            url=url,\n",
    "            headers=headers,\n",
    "            json=json,\n",
    "            files=files,\n",
    "            params=params,\n",
    "            timeout=300  # 5 minute timeout for large file uploads\n",
    "        )\n",
    "        \n",
    "        # Raise an exception for bad status codes\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"âŒ HTTP Error: {e}\")\n",
    "        print(f\"Response content: {response.text}\")\n",
    "        raise\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Request Error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede83720",
   "metadata": {},
   "source": [
    "## 2. Helper Functions for API Requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a20206c-dc87-4f0d-b9cf-87923998a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_campaign(\n",
    "     campaign_data:str,\n",
    "    \n",
    "    token: str,\n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a new campaign.\n",
    "    \n",
    "    Args:\n",
    "        name: Campaign name\n",
    "        description: Campaign description\n",
    "        allocation: TACC allocation identifier (required)\n",
    "        token: Authentication token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the created campaign data with ID\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/api/v1/campaigns\"    \n",
    "    response = make_authenticated_request(\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        token=token,\n",
    "        json=campaign_data\n",
    "    )\n",
    "    \n",
    "    result = response.json()\n",
    "    print(f\"âœ… Campaign created successfully!\")\n",
    "    print(f\"Campaign ID: {result.get('id')}\")\n",
    "\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f94d96",
   "metadata": {},
   "source": [
    "### Creating Campaigns\n",
    "\n",
    "Before uploading CSV data, you need to create a campaign to organize your data collection project. A campaign serves as the top-level container for all related monitoring activities.\n",
    "\n",
    "#### Campaign Requirements\n",
    "\n",
    "**Required Fields:**\n",
    "- `name`: Descriptive name for your data collection project\n",
    "- `description`: Detailed description of the campaign's purpose and scope\n",
    "\n",
    "#### Campaign Best Practices\n",
    "\n",
    "ðŸŽ¯ **Naming Conventions:**\n",
    "- Use descriptive, unique names that clearly identify the project\n",
    "- Include dates, locations, or project codes for easy identification\n",
    "- Examples: \"Austin Air Quality 2024\", \"Hurricane Harvey Recovery Monitoring\"\n",
    "\n",
    "ðŸ“ **Descriptions:**\n",
    "- Provide detailed context about the campaign's objectives\n",
    "- Include information about duration, scope, and expected outcomes\n",
    "- Mention any relevant research or operational goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e618b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Campaign from Configuration ===\n",
      "ðŸ“‹ Campaign Configuration Summary:\n",
      "  Name: Beaumont Stream Gauge\n",
      "  Description: Beaumont Stream Gauge Campaign...\n",
      "âœ… Campaign created successfully!\n",
      "Campaign ID: 10\n",
      "\n",
      "ðŸŽ‰ Campaign setup complete!\n",
      "Campaign ID: 10\n"
     ]
    }
   ],
   "source": [
    "def load_and_create_campaign(\n",
    "    config_path: str = \"campaigns/campaign.json\",\n",
    "    token: str = None,\n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load campaign configuration from JSON and create the campaign.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path to the campaign configuration JSON file\n",
    "        token: Authentication token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the created campaign data with ID\n",
    "    \"\"\"\n",
    "    # Load configuration\n",
    "    with open(config_path) as campaign_data:\n",
    "        campaign_json = json.loads(campaign_data.read())\n",
    "\n",
    "    # Validate required fields\n",
    "    required_fields = [\"name\", \"description\"]\n",
    "    for field in required_fields:\n",
    "        if field not in campaign_json:\n",
    "            raise ValueError(f\"Missing required field '{field}' in campaign config\")\n",
    "    \n",
    "    # Display configuration summary\n",
    "    print(f\"ðŸ“‹ Campaign Configuration Summary:\")\n",
    "    print(f\"  Name: {campaign_json['name']}\")\n",
    "    print(f\"  Description: {campaign_json['description'][:100]}...\")\n",
    "    \n",
    "    if \"metadata\" in campaign_json:\n",
    "        metadata = campaign_json[\"metadata\"]\n",
    "        print(f\"  Project Lead: {metadata.get('project_lead', 'N/A')}\")\n",
    "        print(f\"  Institution: {metadata.get('institution', 'N/A')}\")\n",
    "    \n",
    "    # Create the campaign\n",
    "    campaign = create_campaign(\n",
    "        campaign_data=campaign_json,\n",
    "        token=token,\n",
    "        base_url=base_url\n",
    "    )\n",
    "    return campaign\n",
    "\n",
    "# Usage example\n",
    "print(\"=== Creating Campaign from Configuration ===\")\n",
    "try:\n",
    "    campaign = load_and_create_campaign(\n",
    "        config_path=\"campaigns/campaign.json\",\n",
    "        token=token\n",
    "    )\n",
    "    \n",
    "    campaign_id = campaign['id']\n",
    "    print(f\"\\nðŸŽ‰ Campaign setup complete!\")\n",
    "    print(f\"Campaign ID: {campaign_id}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Configuration file error: {e}\")\n",
    "    print(\"ðŸ’¡ Please create a campaigns/campaign.json file with your campaign details\")\n",
    "except ValueError as e:\n",
    "    print(f\"âŒ Configuration error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Campaign creation failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f364022",
   "metadata": {},
   "source": [
    "### Creating Stations\n",
    "\n",
    "Once you have a campaign, you need to create stations within it. Stations represent specific monitoring locations where sensors collect data.\n",
    "\n",
    "#### Station Requirements\n",
    "\n",
    "**Required Fields:**\n",
    "- `campaign_id`: ID of the parent campaign (must exist)\n",
    "- `name`: Unique name for the monitoring station\n",
    "- `description`: Details about the station location and purpose\n",
    "- `latitude`: Decimal degrees (e.g., 30.2672)\n",
    "- `longitude`: Decimal degrees (e.g., -97.7431)\n",
    "\n",
    "#### Station Best Practices\n",
    "\n",
    "ðŸ“ **Location Data:**\n",
    "- Ensure coordinates are in decimal degrees format\n",
    "- Use WGS84 coordinate system (standard GPS coordinates)\n",
    "- Verify coordinates are accurate for your monitoring location\n",
    "- Test coordinates in mapping software before creating stations\n",
    "\n",
    "ðŸ·ï¸ **Station Naming:**\n",
    "- Use descriptive names that indicate location or purpose\n",
    "- Include geographic references or landmarks\n",
    "- Examples: \"River Bridge Station\", \"Industrial District Monitor\"\n",
    "\n",
    "ðŸ“ **Station Descriptions:**\n",
    "- Describe the physical location and surroundings\n",
    "- Note any special characteristics or constraints\n",
    "- Include installation details or access information\n",
    "\n",
    "#### Alternative: Web Interface for Stations\n",
    "\n",
    "If you prefer using the web interface:\n",
    "\n",
    "1. **Navigate to Campaign:**\n",
    "   - Go to your created campaign in the web portal\n",
    "   - Access the campaign details page\n",
    "\n",
    "2. **Create Station:**\n",
    "   - Go to the \"Stations\" section within the campaign\n",
    "   - Click \"Add Station\"\n",
    "   - Provide station details and coordinates\n",
    "   - Save to get your Station ID\n",
    "\n",
    "3. **Note the Station ID:**\n",
    "   - Copy the Station ID for use in data uploads\n",
    "\n",
    "\n",
    "ðŸ’¡ **Pro Tip:** Save your campaign and station IDs in a configuration file or notebook cell for easy reuse across multiple data uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ee3af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_station(\n",
    "    station_data: Dict[str, Any],\n",
    "    campaign_id: int,\n",
    "    token: str,\n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a new station within a campaign.\n",
    "    \n",
    "    Args:\n",
    "        station_data: Dictionary containing station information\n",
    "        campaign_id: ID of the parent campaign\n",
    "        token: Authentication token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the created station data with ID\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/api/v1/campaigns/{campaign_id}/stations\"\n",
    "    \n",
    "    response = make_authenticated_request(\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        token=token,\n",
    "        json=station_data\n",
    "    )\n",
    "    \n",
    "    result = response.json()\n",
    "    print(f\"âœ… Station created successfully!\")\n",
    "    print(f\"Station ID: {result.get('id')}\")\n",
    "    print(f\"Station Name: {station_data.get('name')}\")\n",
    "    print(f\"Project ID: {station_data.get('projectid')}\")\n",
    "    print(f\"Contact: {station_data.get('contact_name')}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def load_station_config(config_path: str = \"stations/station.json\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load station configuration from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path to the station configuration JSON file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing station configuration data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r', encoding='utf-8') as file:\n",
    "            config = json.load(file)\n",
    "            print(f\"ðŸ“„ Loaded station config from: {config_path}\")\n",
    "            return config\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Station config file not found: {config_path}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON in station config file: {e}\")\n",
    "\n",
    "def load_and_create_station(\n",
    "    campaign_id: int,\n",
    "    config_path: str = \"stations/station.json\",\n",
    "    token: str = None,\n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load station configuration from JSON and create the station.\n",
    "    \n",
    "    Args:\n",
    "        campaign_id: ID of the parent campaign\n",
    "        config_path: Path to the station configuration JSON file\n",
    "        token: Authentication token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the created station data with ID\n",
    "    \"\"\"\n",
    "    # Load configuration\n",
    "    station_config = load_station_config(config_path)\n",
    "    \n",
    "    # Validate required fields\n",
    "    required_fields = [\"name\", \"projectid\", \"description\", \"contact_name\", \"contact_email\", \"active\", \"start_date\"]\n",
    "    for field in required_fields:\n",
    "        if field not in station_config:\n",
    "            raise ValueError(f\"Missing required field '{field}' in station config\")\n",
    "    \n",
    "    # Display configuration summary\n",
    "    print(f\"ðŸ“‹ Station Configuration Summary:\")\n",
    "    print(f\"  Name: {station_config['name']}\")\n",
    "    print(f\"  Project ID: {station_config['projectid']}\")\n",
    "    print(f\"  Description: {station_config['description'][:100]}...\")\n",
    "    print(f\"  Contact: {station_config['contact_name']}\")\n",
    "    print(f\"  Active: {station_config['active']}\")\n",
    "    print(f\"  Start Date: {station_config['start_date']}\")\n",
    "    \n",
    "    # Create the station\n",
    "    station = create_station(\n",
    "        station_data=station_config,\n",
    "        campaign_id=campaign_id,\n",
    "        token=token,\n",
    "        base_url=base_url\n",
    "    )\n",
    "    \n",
    "    return station\n",
    "\n",
    "def load_and_create_multiple_stations(\n",
    "    campaign_id: int,\n",
    "    config_path: str = \"stations/stations.json\",\n",
    "    token: str = None,\n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Load multiple station configurations from JSON and create all stations.\n",
    "    \n",
    "    Args:\n",
    "        campaign_id: ID of the parent campaign\n",
    "        config_path: Path to the stations configuration JSON file\n",
    "        token: Authentication token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing the created station data\n",
    "    \"\"\"\n",
    "    # Load configuration\n",
    "    with open(config_path, 'r', encoding='utf-8') as file:\n",
    "        stations_config = json.load(file)\n",
    "    \n",
    "    created_stations = []\n",
    "    \n",
    "    # Handle both single station and multiple stations format\n",
    "    if \"stations\" in stations_config:\n",
    "        station_list = stations_config[\"stations\"]\n",
    "    else:\n",
    "        station_list = [stations_config]  # Single station format\n",
    "    \n",
    "    print(f\"ðŸ“‹ Creating {len(station_list)} station(s)...\")\n",
    "    \n",
    "    for i, station_config in enumerate(station_list, 1):\n",
    "        print(f\"\\n--- Creating Station {i}/{len(station_list)} ---\")\n",
    "        \n",
    "        try:\n",
    "            station = create_station(\n",
    "                station_data=station_config,\n",
    "                campaign_id=campaign_id,\n",
    "                token=token,\n",
    "                base_url=base_url\n",
    "            )\n",
    "            created_stations.append(station)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to create station '{station_config.get('name', 'Unknown')}': {e}\")\n",
    "            continue\n",
    "    \n",
    "    return created_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3f0d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Single Station from Configuration ===\n",
      "ðŸ“„ Loaded station config from: stations/station.json\n",
      "ðŸ“‹ Station Configuration Summary:\n",
      "  Name: Cow Bayou near Mauriceville\n",
      "  Project ID: SETx-UIFL Beaumont\n",
      "  Description: Beaumont Run stream gauge at Cow Bayou...\n",
      "  Contact: Nick Brake\n",
      "  Active: True\n",
      "  Start Date: 2025-06-02T14:42:00+0000\n",
      "âœ… Station created successfully!\n",
      "Station ID: 14\n",
      "Station Name: Cow Bayou near Mauriceville\n",
      "Project ID: SETx-UIFL Beaumont\n",
      "Contact: Nick Brake\n",
      "\n",
      "ðŸŽ‰ Station setup complete!\n",
      "Station ID: 14\n",
      "\n",
      "==================================================\n",
      "=== Creating Multiple Stations from Configuration ===\n",
      "âŒ Configuration file error: [Errno 2] No such file or directory: 'stations/stations.json'\n",
      "ðŸ’¡ Please create a stations/stations.json file with your station details\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Creating Single Station from Configuration ===\")\n",
    "try:\n",
    "    station = load_and_create_station(\n",
    "        campaign_id=campaign_id,\n",
    "        config_path=\"stations/station.json\",\n",
    "        token=token\n",
    "    )\n",
    "    \n",
    "    station_id = station['id']\n",
    "    print(f\"\\nðŸŽ‰ Station setup complete!\")\n",
    "    print(f\"Station ID: {station_id}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Configuration file error: {e}\")\n",
    "    print(\"ðŸ’¡ Please create a stations/station.json file with your station details\")\n",
    "except ValueError as e:\n",
    "    print(f\"âŒ Configuration error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Station creation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== Creating Multiple Stations from Configuration ===\")\n",
    "try:\n",
    "    stations = load_and_create_multiple_stations(\n",
    "        campaign_id=campaign_id,\n",
    "        config_path=\"stations/stations.json\",\n",
    "        token=token\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Created {len(stations)} station(s) successfully!\")\n",
    "    for station in stations:\n",
    "        print(f\"  â€¢ {station.get('name', 'Unknown')} (ID: {station['id']})\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Configuration file error: {e}\")\n",
    "    print(\"ðŸ’¡ Please create a stations/stations.json file with your station details\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Multiple stations creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ba293",
   "metadata": {},
   "source": [
    "## CSV Data Upload Function Documentation\n",
    "\n",
    "### Overview\n",
    "\n",
    "The `upload_csv_data` function provides a streamlined way to upload sensor and measurement data to the Upstream platform via CSV files. This function handles file validation, authentication, and provides detailed feedback on the upload process.\n",
    "\n",
    "### Function Signature\n",
    "\n",
    "```python\n",
    "def upload_csv_data(\n",
    "    campaign_id: int,\n",
    "    station_id: int,\n",
    "    sensors_file_path: str,\n",
    "    measurements_file_path: str,\n",
    "    token: str,\n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "\n",
    "| Parameter | Type | Required | Description |\n",
    "|-----------|------|----------|-------------|\n",
    "| `campaign_id` | `int` | âœ… | Unique identifier for the target campaign |\n",
    "| `station_id` | `int` | âœ… | Unique identifier for the target station within the campaign |\n",
    "| `sensors_file_path` | `str` | âœ… | Local file path to the sensors CSV file |\n",
    "| `measurements_file_path` | `str` | âœ… | Local file path to the measurements CSV file |\n",
    "| `token` | `str` | âœ… | Authentication token for API access |\n",
    "| `base_url` | `str` | âŒ | Base URL for the Upstream API (defaults to dev environment) |\n",
    "\n",
    "### Return Value\n",
    "\n",
    "Returns a `Dict[str, Any]` containing the upload response data with statistics including:\n",
    "- Total sensors processed\n",
    "- Total measurements added to database\n",
    "- Data processing time\n",
    "\n",
    "### Features\n",
    "\n",
    "#### ðŸ” **File Validation**\n",
    "- Automatically checks if both CSV files exist before attempting upload\n",
    "- Raises `FileNotFoundError` with descriptive messages for missing files\n",
    "\n",
    "#### ðŸ“Š **Progress Tracking**\n",
    "- Displays upload parameters for verification\n",
    "- Shows real-time upload status with emoji indicators\n",
    "- Provides detailed statistics upon completion\n",
    "\n",
    "#### ðŸ” **Secure Upload**\n",
    "- Uses authenticated requests via the `make_authenticated_request` helper\n",
    "- Properly formats files for multipart form data upload\n",
    "\n",
    "#### ðŸŽ¯ **Error Handling**\n",
    "- Pre-upload file existence validation\n",
    "- Clear error messages for troubleshooting\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "```python\n",
    "try:\n",
    "    result = upload_csv_data(\n",
    "        campaign_id=123,\n",
    "        station_id=456,\n",
    "        sensors_file_path=\"./data/sensors.csv\",\n",
    "        measurements_file_path=\"./data/measurements.csv\",\n",
    "        token=\"your_auth_token_here\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Upload successful! {result['Total measurements added to database']} measurements added.\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Upload failed: {e}\")\n",
    "```\n",
    "\n",
    "### API Endpoint\n",
    "\n",
    "The function uploads to the following endpoint:\n",
    "```\n",
    "POST {base_url}/api/v1/uploadfile_csv/campaign/{campaign_id}/station/{station_id}/sensor\n",
    "```\n",
    "\n",
    "### File Format Requirements\n",
    "\n",
    "#### Sensors CSV\n",
    "- Must contain sensor definition data\n",
    "- Uploaded as `upload_file_sensors` form field\n",
    "\n",
    "#### Measurements CSV  \n",
    "- Must contain measurement data corresponding to the sensors\n",
    "- Uploaded as `upload_file_measurements` form field\n",
    "\n",
    "### Console Output Example\n",
    "\n",
    "```\n",
    "=== Uploading CSV Data ===\n",
    "Campaign ID: 123\n",
    "Station ID: 456\n",
    "Sensors file: ./data/sensors.csv\n",
    "Measurements file: ./data/measurements.csv\n",
    "ðŸ“¤ Uploading files...\n",
    "âœ… Upload completed successfully!\n",
    "ðŸ“Š Upload Statistics:\n",
    "  â€¢ Sensors processed: 15\n",
    "  â€¢ Measurements added: 1,250\n",
    "  â€¢ Processing time: 2.3s\n",
    "```\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "- `os` - For file existence checking\n",
    "- `make_authenticated_request` - Custom function for authenticated API calls\n",
    "- `Dict`, `Any` from `typing` - For type hints\n",
    "\n",
    "### Error Scenarios\n",
    "\n",
    "| Error Type | Cause | Solution |\n",
    "|------------|-------|----------|\n",
    "| `FileNotFoundError` | CSV file doesn't exist at specified path | Verify file paths are correct |\n",
    "| Authentication errors | Invalid or expired token | Refresh authentication token |\n",
    "| API errors | Server issues or invalid parameters | Check campaign/station IDs and API status |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Validate Data First**: Ensure your CSV files are properly formatted before upload\n",
    "2. **Check Permissions**: Verify you have write access to the specified campaign/station\n",
    "3. **Monitor Output**: Pay attention to the upload statistics to confirm expected data volumes\n",
    "4. **Handle Errors**: Always wrap calls in try-catch blocks for production use\n",
    "5. **Use Absolute Paths**: Prefer absolute file paths to avoid path resolution issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3ba22-8018-4d8d-86ed-04fb62ebc6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def upload_csv_data(\n",
    "    campaign_id: int,\n",
    "    station_id: int,\n",
    "    sensors_file_path: str,\n",
    "    measurements_file_path: str,\n",
    "    token: str,\n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Upload sensor and measurement CSV files to Upstream.\n",
    "    \n",
    "    Args:\n",
    "        campaign_id: ID of the target campaign\n",
    "        station_id: ID of the target station\n",
    "        sensors_file_path: Path to sensors CSV file\n",
    "        measurements_file_path: Path to measurements CSV file\n",
    "        token: Access token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        Upload response data\n",
    "    \"\"\"\n",
    "    upload_url = f\"{base_url}/api/v1/uploadfile_csv/campaign/{campaign_id}/station/{station_id}/sensor\"\n",
    "    \n",
    "    print(f\"=== Uploading CSV Data ===\")\n",
    "    print(f\"Campaign ID: {campaign_id}\")\n",
    "    print(f\"Station ID: {station_id}\")\n",
    "    print(f\"Sensors file: {sensors_file_path}\")\n",
    "    print(f\"Measurements file: {measurements_file_path}\")\n",
    "    \n",
    "    # Verify files exist\n",
    "    if not os.path.exists(sensors_file_path):\n",
    "        raise FileNotFoundError(f\"Sensors file not found: {sensors_file_path}\")\n",
    "    if not os.path.exists(measurements_file_path):\n",
    "        raise FileNotFoundError(f\"Measurements file not found: {measurements_file_path}\")\n",
    "    \n",
    "    # Prepare files for upload\n",
    "    with open(sensors_file_path, 'rb') as sensors_file, \\\n",
    "         open(measurements_file_path, 'rb') as measurements_file:\n",
    "        \n",
    "        files = {\n",
    "            'upload_file_sensors': ('sensors.csv', sensors_file, 'text/csv'),\n",
    "            'upload_file_measurements': ('measurements.csv', measurements_file, 'text/csv')\n",
    "        }\n",
    "        \n",
    "        print(\"ðŸ“¤ Uploading files...\")\n",
    "        response = make_authenticated_request(\n",
    "            method=\"POST\",\n",
    "            url=upload_url,\n",
    "            token=token,\n",
    "            files=files\n",
    "        )\n",
    "        \n",
    "        result = response.json()\n",
    "        print(\"âœ… Upload completed successfully!\")\n",
    "        \n",
    "        # Display upload statistics\n",
    "        print(f\"ðŸ“Š Upload Statistics:\")\n",
    "        print(f\"  â€¢ Sensors processed: {result.get('Total sensors processed', 'N/A')}\")\n",
    "        print(f\"  â€¢ Measurements added: {result.get('Total measurements added to database', 'N/A')}\")\n",
    "        print(f\"  â€¢ Processing time: {result.get('Data Processing time', 'N/A')}\")\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c765ce",
   "metadata": {},
   "source": [
    "### CSV File Format Examples\n",
    "\n",
    "#### Sensors CSV Format\n",
    "\n",
    "Your `sensors.csv` file defines the sensor metadata and should follow this structure:\n",
    "\n",
    "```csv\n",
    "alias,variablename,units,postprocess,postprocessscript\n",
    "temp_sensor_01,Air Temperature,Â°C,,\n",
    "humidity_01,Relative Humidity,%,,\n",
    "pressure_01,Atmospheric Pressure,hPa,,\n",
    "wind_speed_01,Wind Speed,m/s,true,wind_correction_script\n",
    "```\n",
    "\n",
    "**Column Descriptions:**\n",
    "- `alias`: Unique identifier for the sensor (used as column header in measurements)\n",
    "- `variablename`: Human-readable description of what the sensor measures\n",
    "- `units`: Measurement units (e.g., Â°C, %, hPa, m/s)\n",
    "- `postprocess`: Boolean flag indicating if post-processing is required\n",
    "- `postprocessscript`: Name of the post-processing script (if applicable)\n",
    "\n",
    "#### Measurements CSV Format\n",
    "\n",
    "Your `measurements.csv` file contains the actual sensor data and should follow this structure:\n",
    "\n",
    "```csv\n",
    "collectiontime,Lat_deg,Lon_deg,temp_sensor_01,humidity_01,pressure_01,wind_speed_01\n",
    "2024-01-15T10:30:00,30.2672,-97.7431,23.5,65.2,1013.25,2.3\n",
    "2024-01-15T10:31:00,30.2673,-97.7432,23.7,64.8,1013.20,2.1\n",
    "2024-01-15T10:32:00,30.2674,-97.7433,23.9,64.5,1013.15,1.8\n",
    "2024-01-15T10:33:00,30.2675,-97.7434,,64.2,1013.10,1.9\n",
    "```\n",
    "\n",
    "**Required Columns:**\n",
    "- `collectiontime`: Timestamp in ISO 8601 format (YYYY-MM-DDTHH:MM:SS)\n",
    "- `Lat_deg`: Latitude in decimal degrees\n",
    "- `Lon_deg`: Longitude in decimal degrees\n",
    "\n",
    "**Sensor Data Columns:**\n",
    "- Each sensor `alias` from sensors.csv becomes a column header\n",
    "- Column names must exactly match the sensor aliases\n",
    "- Empty values are automatically handled (see row 4 in example)\n",
    "\n",
    "#### Important File Format Notes\n",
    "\n",
    "âš ï¸ **Critical Requirements:**\n",
    "- Each sensor `alias` from sensors.csv becomes a column in measurements.csv\n",
    "- `collectiontime`, `Lat_deg`, and `Lon_deg` are required columns in measurements.csv\n",
    "- Empty values are handled automatically by the system\n",
    "- Maximum file size is **500 MB per file**\n",
    "- Use UTF-8 encoding for both files\n",
    "- Timestamps should be in UTC or include timezone information\n",
    "\n",
    "ðŸ“ **Best Practices:**\n",
    "- Keep sensor aliases short but descriptive\n",
    "- Use consistent naming conventions (e.g., `sensor_type_number`)\n",
    "- Ensure measurement values match the units specified in sensors.csv\n",
    "- Include all sensors in measurements.csv even if some readings are missing\n",
    "\n",
    "### Additional Helper Functions\n",
    "\n",
    "#### Get Available Campaigns\n",
    "\n",
    "```python\n",
    "def get_campaigns(\n",
    "    token: str, \n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get list of available campaigns.\n",
    "    \n",
    "    Args:\n",
    "        token: Authentication token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing campaign data\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/api/v1/campaigns\"\n",
    "    response = make_authenticated_request(\"GET\", url, token)\n",
    "    return response.json()\n",
    "```\n",
    "\n",
    "#### Get Campaign Stations\n",
    "\n",
    "```python\n",
    "def get_stations(\n",
    "    campaign_id: int, \n",
    "    token: str, \n",
    "    base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get list of stations for a specific campaign.\n",
    "    \n",
    "    Args:\n",
    "        campaign_id: ID of the target campaign\n",
    "        token: Authentication token\n",
    "        base_url: Base URL for the API\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing station data for the campaign\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/api/v1/campaigns/{campaign_id}/stations\"\n",
    "    response = make_authenticated_request(\"GET\", url, token)\n",
    "    return response.json()\n",
    "```\n",
    "\n",
    "#### Usage Example: Exploring Available Resources\n",
    "\n",
    "```python\n",
    "# Example: List available campaigns and stations\n",
    "print(\"=== Available Campaigns ===\")\n",
    "campaigns = get_campaigns(token)\n",
    "print(json.dumps(campaigns, indent=2))\n",
    "\n",
    "print(\"\\n=== Available Stations ===\")\n",
    "stations = get_stations(CAMPAIGN_ID, token)\n",
    "print(json.dumps(stations, indent=2))\n",
    "\n",
    "# Find the right campaign and station IDs\n",
    "for campaign in campaigns.get('data', []):\n",
    "    print(f\"Campaign: {campaign['name']} (ID: {campaign['id']})\")\n",
    "    \n",
    "    # Get stations for this campaign\n",
    "    campaign_stations = get_stations(campaign['id'], token)\n",
    "    for station in campaign_stations.get('data', []):\n",
    "        print(f\"  â””â”€â”€ Station: {station['name']} (ID: {station['id']})\")\n",
    "```\n",
    "\n",
    "#### Helper Function Features\n",
    "\n",
    "ðŸ” **Campaign Discovery:**\n",
    "- List all campaigns you have access to\n",
    "- View campaign metadata and descriptions\n",
    "- Identify the correct campaign ID for your data\n",
    "\n",
    "ðŸ—ï¸ **Station Management:**\n",
    "- List all stations within a campaign\n",
    "- View station details and locations\n",
    "- Find the appropriate station ID for your sensors\n",
    "\n",
    "ðŸ’¡ **Integration Tip:**\n",
    "Use these helper functions before uploading data to ensure you're targeting the correct campaign and station IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2d17b-abd9-4193-be54-2d43236e7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_campaigns(token: str, base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\") -> Dict[str, Any]:\n",
    "    \"\"\"Get list of available campaigns.\"\"\"\n",
    "    url = f\"{base_url}/api/v1/campaigns\"\n",
    "    response = make_authenticated_request(\"GET\", url, token)\n",
    "    return response.json()\n",
    "\n",
    "def get_stations(campaign_id: int, token: str, base_url: str = \"https://upstream-dso.tacc.utexas.edu/dev\") -> Dict[str, Any]:\n",
    "    \"\"\"Get list of stations for a campaign.\"\"\"\n",
    "    url = f\"{base_url}/api/v1/campaigns/{campaign_id}/stations\"\n",
    "    response = make_authenticated_request(\"GET\", url, token)\n",
    "    return response.json()\n",
    "\n",
    "# Example: List available campaigns and stations\n",
    "\"\"\"\n",
    "print(\"=== Available Campaigns ===\")\n",
    "campaigns = get_campaigns(token)\n",
    "print(json.dumps(campaigns, indent=2))\n",
    "\n",
    "print(\"=== Available Stations ===\")\n",
    "stations = get_stations(CAMPAIGN_ID, token)\n",
    "print(json.dumps(stations, indent=2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2fa823",
   "metadata": {},
   "source": [
    "## 7. Best Practices\n",
    "\n",
    "1. **File Preparation:**\n",
    "   - Validate your CSV files before upload\n",
    "   - Ensure sensor aliases match between files\n",
    "   - Use consistent timestamp formats\n",
    "\n",
    "2. **Error Handling:**\n",
    "   - Always wrap API calls in try-catch blocks\n",
    "   - Check file existence before upload\n",
    "   - Validate response status codes\n",
    "\n",
    "3. **Security:**\n",
    "   - Never hardcode credentials in notebooks\n",
    "   - Store tokens securely\n",
    "   - Use environment variables for sensitive data\n",
    "\n",
    "4. **Performance:**\n",
    "   - Keep files under 500 MB for optimal performance\n",
    "   - Use batch uploads for large datasets\n",
    "   - Monitor upload progress and statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
